{"cells":[{"cell_type":"markdown","source":["## First Model - Linear Regression\n\n- __Group name__: PretendCoders\n- __Author names__: \n- Rita Zhang  - zhang_hong@bentley.edu\n- Anthony Arno  - arn1_anth@bentley.edu\n- Vibutesh Ravisankar  - ravison_vibu@bentley.edu"],"metadata":{}},{"cell_type":"code","source":["%sh ls /dbfs/mnt/group-ma755/data/ais*"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/dbfs/mnt/group-ma755/data/ais-test.csv\n/dbfs/mnt/group-ma755/data/ais-train.csv\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["%run \"/Courses/MA755/Groups/pretendcoders/Final Notebooks/A3.0 - Feature Engineering\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["Import `numpy`,`pandas`,`sklearn`. Note the corresponding versions."],"metadata":{}},{"cell_type":"code","source":["import numpy             as np\nimport pandas            as pd\nimport sklearn as sk\n\n\nfrom pandas import Series\nfrom pandas import DataFrame\nfrom sklearn import pipeline\nfrom sklearn import preprocessing\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn_pandas import gen_features\nimport sklearn.preprocessing, sklearn.decomposition, \\\n       sklearn.linear_model,  sklearn.pipeline, \\\n       sklearn.metrics\nfrom sklearn.model_selection import GridSearchCV\n\nnp.__version__, pd.__version__, sk.__version__"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">19</span><span class=\"ansired\">]: </span>(&apos;1.14.3&apos;, &apos;0.18.1&apos;, &apos;0.18.1&apos;)\n</div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["Create the training target value `import_t_y`"],"metadata":{}},{"cell_type":"code","source":["import_t_y = np.array(ais_t_df.Average.shift(-5))\nwhere_nan=np.isnan(import_t_y)\nimport_t_y[where_nan]=0"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["import_test_y = np.array(ais_testnew_df.Average.shift(-5))\nwhere_nan1=np.isnan(import_test_y)\nimport_test_y[where_nan1]=0"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["from sklearn import pipeline\nfrom sklearn.linear_model  import LinearRegression\nbinarizer_list=[['Month'],['Day']]\nexternal_data_list=[['DJIA'],['Crude Oil Price'],['Dollar Index'],['Indicator']]\nmlpipeline = pipeline.Pipeline([('Date', DateTransformer()),\n                               ('Unique', UniqueTransformer()),\n                               ('AppendYearMonthDay', AddDatesTransformer()),\n                               ('MergeFeatures', MergeFeaturesTransformer()),\n                               ('MergeFeatures2', MergeFeaturesTransformer(df_name=CrudeOil_df)),\n                               ('MergeFeatures3', MergeFeaturesTransformer(df_name=DollarIndex_df)), \n                               ('MergeFeatures4', MergeFeaturesTransformer(df_name=China_Recession_Binary_df)),   \n                               ('Type', TypeTransformer(col_name='DJIA')),\n                               ('Type2', TypeTransformer(col_name='Crude Oil Price')),\n                               ('Type3', TypeTransformer(col_name='Dollar Index')),\n                               \n                               ('feature', FeatureUnion([('lags',mapper_lags(n_lags=75,col_name='Average')),\n                                                         ('class', DataFrameMapper( \n                                                                   gen_features(columns=binarizer_list,\n                                                                   classes=[sklearn.preprocessing.LabelBinarizer]),\n                                                                   input_df=True)),\n                                                         ('new_data', DataFrameMapper(\n                                                                     gen_features(columns=external_data_list,\n                                                                     classes=None),input_df=True)),\n                                                         ('windows',mapper_window(col_name='Average')),\n                                                         ('windows2',mapper_window(col_name='DJIA'))\n                                                                             ])),\n                               ('align',  NaNTransformer()),\n                               ('lin',     LinearRegression())\n                              ])\nparameters = {'lin__fit_intercept':[True,False], \n              'lin__normalize'    :[True,False], \n              'lin__copy_X'       :[True,False]}\ngrid = GridSearchCV(estimator =mlpipeline, \n                    param_grid=parameters, \n                    cv        =KFold(n_splits=3, shuffle=True))\ngrid.fit(ais_t_df, import_t_y)\ny_pred=grid.predict(ais_testnew_df)\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nprint(\"MSE :\", mean_squared_error(import_test_y, \n                                   y_pred))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">MSE : 32858959.970493697\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["Creating the prediction of the testing data using the `mlpipeline` defined in the cell above. Fit the pipeline to the training data and create predictions from the test dataset."],"metadata":{}},{"cell_type":"code","source":["import_tst_predict = mlpipeline.fit(ais_train_df,\n                                  import_t_y)\\\n                                .predict(ais_test_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["Create the test target value `import_test_y`"],"metadata":{}},{"cell_type":"code","source":["import_test_y = np.array(ais_testnew_df.Average.shift(-5))\nwhere_nan1=np.isnan(import_test_y)\nimport_test_y[where_nan1]=0"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["Here we are using the zip command to put the y values and predictions of the testing data side by side. Thus, enabling us to compare the values rather easily."],"metadata":{}},{"cell_type":"code","source":["list(zip(import_test_y, \n         import_tst_predict))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">53</span><span class=\"ansired\">]: </span>\n[(3594.0, -14357.602199411907),\n (3261.0, -16832.49853720478),\n (3101.0, -16794.801940118094),\n (2941.0, -16972.603226673178),\n (2748.0, -16187.749616244255),\n (2730.0, -15780.369309873888),\n (2662.0, -15557.778892598973),\n (2706.0, -14675.91092958617),\n (2808.0, -14432.019469263498),\n (2984.0, -15657.733623262262),\n (3184.0, -4919.707605555199),\n (3118.0, -6700.603539934487),\n (3063.0, -7086.067551687931),\n (2851.0, -7316.985128472817),\n (2785.0, -6800.907317180292),\n (2806.0, -7451.168388386821),\n (2822.0, -7504.250690383826),\n (2775.0, -6286.542445574061),\n (2743.0, -7193.705761487017),\n (2824.0, -7150.918640656168),\n (2781.0, -7776.570830212815),\n (2771.0, -7220.143093000788),\n (2776.0, -7652.997438184673),\n (2756.0, -7565.509700210812),\n (2698.0, -8256.112466649673),\n (2721.0, -8301.834799325672),\n (2805.0, -8232.549359364722),\n (2799.0, -8346.69858020666),\n (2772.0, -8033.180253096023),\n (2642.0, -7569.421987141297),\n (2578.0, -4932.664703582141),\n (2507.0, -5449.46197421844),\n (2477.0, -5565.2765293931625),\n (2457.0, -6626.852734630895),\n (2396.0, -6854.03586406785),\n (2356.0, -7115.804524364332),\n (2327.0, -7682.903272800035),\n (2291.0, -7702.56115959051),\n (2236.0, -7658.134441776248),\n (2221.0, -7447.58002559924),\n (2185.0, -7109.321051843155),\n (2286.0, -8565.072088072771),\n (2252.0, -8158.644359325135),\n (2218.0, -8569.45062848824),\n (2172.0, -8359.770877701721),\n (2158.0, -9988.811480095275),\n (2211.0, -9009.770669820398),\n (2034.0, -9013.589337465353),\n (1985.0, -9315.590446361559),\n (2036.0, -9076.549229457029),\n (2031.0, -8050.920434263295),\n (1994.0, -8599.19371711923),\n (2005.0, -8549.57757514877),\n (2082.0, -8376.343280107372),\n (2099.0, -9120.625861667737),\n (2151.0, -9585.67563339119),\n (2518.0, -9424.763793467195),\n (3013.0, -9898.467070873448),\n (3512.0, -9772.56953562863),\n (3840.0, -9005.37255271343),\n (4027.0, -8944.678855338338),\n (4533.0, -8785.637121138694),\n (5089.0, -8428.82918586937),\n (5533.0, -7456.469334195244),\n (5537.0, -7981.512888150297),\n (5515.0, -8391.312609975204),\n (6184.0, -8167.433952201369),\n (7076.0, -6690.197461502372),\n (7739.0, -5948.716378002784),\n (8024.0, -5628.402228172075),\n (7745.0, -5196.84772705365),\n (7639.0, -4194.806432114714),\n (8216.0, -3879.243797831641),\n (8276.0, -3826.839381559821),\n (8789.0, -3590.9526548962276),\n (9170.0, -4401.861496860642),\n (9050.0, -4849.4321045596225),\n (8891.0, -3962.4277986333327),\n (8309.0, -4343.847746372885),\n (7418.0, -3361.207603181734),\n (7175.0, -2474.233153804431),\n (7024.0, -3026.8155736630506),\n (6613.0, -3548.282141456155),\n (5946.0, -5229.329664409204),\n (5521.0, -6045.3807979109115),\n (5552.0, -6815.340456667298),\n (6286.0, -7589.1269496760215),\n (6740.0, -7371.804067530284),\n (7791.0, -8339.357934710984),\n (7729.0, -8541.526582672719),\n (7378.0, -7958.987679184014),\n (6981.0, -6553.022827778623),\n (6946.0, -6268.3544935310565),\n (6726.0, -4730.15880197801),\n (6281.0, -5977.232299116316),\n (6175.0, -6506.986585276922),\n (6346.0, -7005.389523292462),\n (6538.0, -7262.163127507651),\n (6541.0, -7357.873645151041),\n (6438.0, -7645.016004793099),\n (6754.0, -7366.435130911639),\n (6789.0, -6526.729624317668),\n (6769.0, -7001.390196096989),\n (7054.0, -6631.310944013567),\n (7164.0, -6206.8420248023685),\n (7241.0, -5962.458291250376),\n (7274.0, -6990.957179960205),\n (7329.0, -7298.281904058647),\n (7170.0, -5985.702697751149),\n (6938.0, -5905.001826781103),\n (6533.0, -6038.1916029051645),\n (6315.0, -4842.078464021652),\n (6108.0, -4573.955674279619),\n (6107.0, -5350.77164221718),\n (6253.0, -5499.334957874882),\n (6452.0, -5938.802102061447),\n (6491.0, -7125.151878732831),\n (6595.0, -7574.571538654382),\n (6784.0, -7320.771722417856),\n (7110.0, -7608.099270746483),\n (7353.0, -7254.85408435604),\n (7490.0, -6156.910613082502),\n (7386.0, -6086.4695298324),\n (7265.0, -6063.78512273512),\n (7188.0, -5697.737604790214),\n (7149.0, -6187.290910574942),\n (7085.0, -3282.776097487891),\n (7044.0, -5909.113794777681),\n (7369.0, -6607.13338273736),\n (7529.0, -7030.633586165088),\n (7548.0, -6210.270808184239),\n (7481.0, -5894.4349523378405),\n (7258.0, -5233.380197641105),\n (6859.0, -4433.615407150533),\n (6632.0, -4065.7642067801244),\n (6498.0, -4718.897947091737),\n (6320.0, -5477.211454586206),\n (6059.0, -5727.16885442059),\n (5723.0, -6385.08332111243),\n (5530.0, -6764.344723858001),\n (5440.0, -6640.114556303506),\n (5354.0, -6974.840767482685),\n (5369.0, -7049.910033472686),\n (5369.0, -6831.361784209057),\n (5363.0, -7087.767744918554),\n (5446.0, -7352.91944509801),\n (5497.0, -7823.359771564956),\n (5357.0, -7150.04153520444),\n (5503.0, -7361.905709033857),\n (5791.0, -7064.184325178856),\n (6236.0, -7668.171185865114),\n (6457.0, -7534.162020496773),\n (6507.0, -7552.811688170415),\n (6214.0, -7446.631107198595),\n (5962.0, -6733.392693485963),\n (5846.0, -5681.718288978409),\n (5885.0, -5400.988615100832),\n (6008.0, -5181.371468766476),\n (6460.0, -5553.413881594017),\n (6826.0, -6728.099924606999),\n (6921.0, -6794.838392284873),\n (6808.0, -6844.289098226152),\n (6730.0, -7115.722095125318),\n (6831.0, -6522.891846914157),\n (7191.0, -6087.809005637922),\n (7459.0, -5862.75612421635),\n (8288.0, -5721.561834339678),\n (9408.0, -6050.966425356673),\n (10170.0, -5108.625763719108),\n (10649.0, -4102.918634182832),\n (10725.0, -2366.8875504841853),\n (10606.0, -3721.6463048509686),\n (9258.0, -2877.93386949681),\n (9618.0, -1291.8376817552562),\n (10929.0, -678.6560392814717),\n (12167.0, -97.0594900074284),\n (13153.0, 150.2505306638268),\n (14366.0, -1480.8294334079328),\n (15301.0, -1247.4617307102162),\n (15202.0, 553.7824170775057),\n (14787.0, 1020.7093343319211),\n (14540.0, 1692.879868232245),\n (13849.0, 2829.959867013873),\n (13069.0, 3955.6457965299414),\n (12710.0, 2942.0006169111075),\n (12425.0, 2941.0105499585698),\n (12380.0, 3524.2534140204807),\n (12773.0, 2574.2192538248273),\n (14443.0, 1475.5119966983257),\n (14622.0, 944.0110410427442),\n (14571.0, -287.42145684816205),\n (14486.0, -294.1209092051431),\n (13783.0, -752.6705767000021),\n (12770.0, 792.8128474454206),\n (12744.0, 255.0783403603782),\n (12644.0, 465.14187923198915),\n (12203.0, 1312.8627210963023),\n (11244.0, 860.7031055211191),\n (10123.0, 234.28964291328157),\n (9659.0, 712.2715852495821),\n (9128.0, 1431.4661032412769),\n (8394.0, -11.737564622242644),\n (7936.0, -1206.277799530726),\n (7763.0, -2680.6135671137017),\n (9056.0, -3153.8432614011326),\n (9949.0, -3762.2785997929896),\n (9369.0, -4283.064621931888),\n (9334.0, -4060.4007272438976),\n (9893.0, -3421.657988143903),\n (10141.0, -1795.6402477548327),\n (10733.0, -1467.9972221471544),\n (12159.0, -3381.1069785119107),\n (13606.0, -2335.047744065938),\n (14094.0, -1757.7043344871054),\n (16269.0, -1276.7296483757164),\n (16526.0, -1883.5351149785201),\n (16299.0, 889.2129747220242),\n (17499.0, 2415.4097524414465),\n (19515.0, 2493.7576086514055),\n (19364.0, 4832.8033063720795),\n (18353.0, 6442.440143614913),\n (17817.0, 5567.878276838517),\n (17035.0, 7503.468830776317),\n (15836.0, 10086.428877650189),\n (14882.0, 8320.7822617877),\n (14836.0, 6467.153954354253),\n (15168.0, 6091.024696567143),\n (14812.0, 4502.667941586806),\n (14259.0, 4949.025081628075),\n (14061.0, 2440.9944640849244),\n (13613.0, 3629.65571540521),\n (12938.0, 3581.8866522875287),\n (11893.0, 2601.8958283456777),\n (10354.0, -397.6610946221117),\n (9342.0, 59.71731154916051),\n (8740.0, -1249.6371766333832),\n (8353.0, -2332.3283868970284),\n (7133.0, -3234.1972290285958),\n (6570.0, -3535.1464251360594),\n (6729.0, -3964.3751480865903),\n (6729.0, -3857.243147341789),\n (6873.0, -3624.2601176613753),\n (8040.0, -4581.170874434298),\n (8605.0, -5371.703917554587),\n (10078.0, -4635.443054317242),\n (11277.0, -5366.444486918968),\n (12410.0, -5016.054829423367),\n (13176.0, -3462.2916248889596),\n (12345.0, -2647.7645127305586),\n (11796.0, -1201.5885259328861),\n (10787.0, -218.07620935996965),\n (9468.0, 1338.4982341219948),\n (9524.0, 1377.455179145065),\n (10343.0, -496.7805461570606),\n (11002.0, -163.2723281797298),\n (11155.0, -1430.0701013303842),\n (12512.0, -2728.6900896277803),\n (12334.0, -1816.12091926633),\n (11915.0, -594.3553419710734),\n (11689.0, 1769.042511327003),\n (10789.0, -247.47221375205118),\n (10006.0, 261.32553473657026),\n (9314.0, -493.9275012233338),\n (8987.0, -1896.3190887750607),\n (8712.0, -1535.8270495539182),\n (8515.0, -2454.247232735368),\n (0.0, -2785.120039965801),\n (0.0, -3321.738125146152),\n (0.0, -3025.535953531322),\n (0.0, -3533.8444008926635),\n (0.0, -4225.327395134391)]\n</div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["In the command below, we are using the `sklearn.metrics` package to calculate the Mean Squared Error, Root Mean Squared Error, the Mean Absolute Error and the Coefficient of Determination which calculates the amount of variation in the prediction that is explained by the variables in the model."],"metadata":{}},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nprint(\"MSE :\", mean_squared_error(import_test_y, \n                                 import_tst_predict))\nprint(\"RMSE:\", np.sqrt(mean_squared_error(import_test_y, \n                                          import_tst_predict)))\nprint(\"MAE :\", mean_absolute_error(import_test_y, \n                                   import_tst_predict))\nprint(\"R2  :\", r2_score(import_test_y,\n                        import_tst_predict))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">MSE : 155991257.69344714\nRMSE: 12489.646019541433\nMAE : 12195.322537947211\nR2  : -8.077072849479487\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["As there is never enough data to train your model, removing a part of it for validation poses a problem of underfitting. By reducing the training data, we risk losing important patterns/ trends in data set, which in turn increases error induced by bias. So, what we require is a method that provides ample data for training the model and also leaves ample data for validation. K Fold cross validation does exactly that which we have performed on our decision tree model. \n\nIn Cross Validation, data is divided into k subsets. such that each time, one of the k subsets is used as the test set/ validation set and the other k-1 subsets are put together to form a training set. The error estimation is averaged over all k trials to get total effectiveness of our model.This significantly reduces bias as we are using most of the data for fitting, and also significantly reduces variance as most of the data is also being used in validation set"],"metadata":{}},{"cell_type":"code","source":["from sklearn.model_selection import cross_val_score, KFold\nscores = cross_val_score(mlpipeline, \n                         ais_t_df, \n                         import_t_y,\n                         scoring=\"neg_mean_squared_error\", \n                         cv=KFold(n_splits=3, shuffle=True))\nrmse_scores = np.sqrt(-scores)\nrmse_scores"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">31</span><span class=\"ansired\">]: </span>array([2877.08102811, 5101.836533  , 2761.87305251])\n</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["Grid Search"],"metadata":{}},{"cell_type":"markdown","source":["In the next cell we are using the `sklearn.model_selection` package to define / create the hyper-parameter dictionary which we will be using in our grid analysis. Hyperparameter is basically a parameter whose value is set before the learning process even begins."],"metadata":{}},{"cell_type":"code","source":["parameters = {'lin__fit_intercept':[True,False], \n              'lin__normalize'    :[True,False], \n              'lin__copy_X'       :[True,False]}\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["In the cell below, we are creating a grid from the estimator pipeline and the hyper-parameter dictionary definied in the command above."],"metadata":{}},{"cell_type":"code","source":["grid = GridSearchCV(estimator =mlpipeline, \n                    param_grid=parameters, \n                    cv        =KFold(n_splits=3, shuffle=True))\ngrid"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">39</span><span class=\"ansired\">]: </span>\nGridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n       error_score=&apos;raise&apos;,\n       estimator=Pipeline(steps=[(&apos;Date&apos;, DateTransformer(col_name=&apos;Average&apos;)), (&apos;Unique&apos;, UniqueTransformer(my_var=False)), (&apos;AppendYearMonthDay&apos;, AddDatesTransformer(my_var=False)), (&apos;MergeFeatures&apos;, MergeFeaturesTransformer(df_name=           Date      DJIA\n0    2012-01-03  12397.38\n1    2012-01-04  12418.42\n2    2012-01-..._var=False)), (&apos;lin&apos;, LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))]),\n       fit_params={}, iid=True, n_jobs=1,\n       param_grid={&apos;lin__fit_intercept&apos;: [True, False], &apos;lin__copy_X&apos;: [True, False], &apos;lin__normalize&apos;: [True, False]},\n       pre_dispatch=&apos;2*n_jobs&apos;, refit=True, return_train_score=True,\n       scoring=None, verbose=0)\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["In the cell below we are fitting the `grid`to the training dataframe and training target dataframe."],"metadata":{}},{"cell_type":"code","source":["grid.fit(ais_t_df, \n         import_t_y)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">40</span><span class=\"ansired\">]: </span>\nGridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n       error_score=&apos;raise&apos;,\n       estimator=Pipeline(steps=[(&apos;Date&apos;, DateTransformer(col_name=&apos;Average&apos;)), (&apos;Unique&apos;, UniqueTransformer(my_var=False)), (&apos;AppendYearMonthDay&apos;, AddDatesTransformer(my_var=False)), (&apos;MergeFeatures&apos;, MergeFeaturesTransformer(df_name=           Date      DJIA\n0    2012-01-03  12397.38\n1    2012-01-04  12418.42\n2    2012-01-..._var=False)), (&apos;lin&apos;, LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))]),\n       fit_params={}, iid=True, n_jobs=1,\n       param_grid={&apos;lin__fit_intercept&apos;: [True, False], &apos;lin__copy_X&apos;: [True, False], &apos;lin__normalize&apos;: [True, False]},\n       pre_dispatch=&apos;2*n_jobs&apos;, refit=True, return_train_score=True,\n       scoring=None, verbose=0)\n</div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["Here we are gathering and evaluating the best hyper-parameters selected by the grid search process."],"metadata":{}},{"cell_type":"code","source":["grid.best_params_ "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">41</span><span class=\"ansired\">]: </span>{&apos;lin__copy_X&apos;: True, &apos;lin__normalize&apos;: False, &apos;lin__fit_intercept&apos;: True}\n</div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["Here we are printing the coefficient of determination (R sq) and also creating a list of the y and predicted target numbers for swift comparison of our model results."],"metadata":{}},{"cell_type":"code","source":["print(\"r squared / variance   : \", grid.best_score_)\n\nnp.round(list(zip(import_test_y, \n                  grid.predict(ais_testnew_df))),\n         decimals=3\n        )[:100,:]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">r squared / variance   :  0.8390252144129577\n<span class=\"ansired\">Out[</span><span class=\"ansired\">44</span><span class=\"ansired\">]: </span>\narray([[ 3594.   , -1617.845],\n       [ 3261.   , -2279.233],\n       [ 3101.   , -2618.531],\n       [ 2941.   , -3270.433],\n       [ 2748.   , -2691.604],\n       [ 2730.   , -2267.493],\n       [ 2662.   , -1983.477],\n       [ 2706.   , -1441.477],\n       [ 2808.   , -1535.65 ],\n       [ 2984.   , -2002.751],\n       [ 3184.   ,  1729.935],\n       [ 3118.   ,   260.468],\n       [ 3063.   ,    30.558],\n       [ 2851.   ,  -248.049],\n       [ 2785.   ,   159.007],\n       [ 2806.   ,   131.152],\n       [ 2822.   ,   352.701],\n       [ 2775.   ,   907.435],\n       [ 2743.   ,   747.017],\n       [ 2824.   ,   461.258],\n       [ 2781.   ,   568.054],\n       [ 2771.   ,  1136.004],\n       [ 2776.   ,  1111.457],\n       [ 2756.   ,  1156.939],\n       [ 2698.   ,   644.021],\n       [ 2721.   ,   198.789],\n       [ 2805.   ,   420.82 ],\n       [ 2799.   ,   253.185],\n       [ 2772.   ,   598.284],\n       [ 2642.   ,  1075.294],\n       [ 2578.   ,  2803.186],\n       [ 2507.   ,  2431.329],\n       [ 2477.   ,  2360.57 ],\n       [ 2457.   ,  1574.256],\n       [ 2396.   ,  1446.001],\n       [ 2356.   ,  1188.379],\n       [ 2327.   ,   685.804],\n       [ 2291.   ,   564.405],\n       [ 2236.   ,   621.135],\n       [ 2221.   ,   947.03 ],\n       [ 2185.   ,  1604.433],\n       [ 2286.   ,  -257.513],\n       [ 2252.   ,   274.788],\n       [ 2218.   ,   213.178],\n       [ 2172.   ,   308.306],\n       [ 2158.   , -1355.098],\n       [ 2211.   ,  -644.318],\n       [ 2034.   ,  -423.559],\n       [ 1985.   ,  -691.009],\n       [ 2036.   ,  -357.7  ],\n       [ 2031.   ,   535.237],\n       [ 1994.   ,    65.492],\n       [ 2005.   ,   303.796],\n       [ 2082.   ,   410.464],\n       [ 2099.   ,  -148.166],\n       [ 2151.   ,  -571.494],\n       [ 2518.   ,  -319.385],\n       [ 3013.   ,  -753.185],\n       [ 3512.   ,  -776.006],\n       [ 3840.   ,   385.744],\n       [ 4027.   ,   262.644],\n       [ 4533.   ,   272.765],\n       [ 5089.   ,  -232.153],\n       [ 5533.   ,   947.453],\n       [ 5537.   ,   637.776],\n       [ 5515.   ,   217.528],\n       [ 6184.   ,   112.384],\n       [ 7076.   ,  1286.664],\n       [ 7739.   ,  2134.245],\n       [ 8024.   ,  2607.233],\n       [ 7745.   ,  3166.614],\n       [ 7639.   ,  3703.3  ],\n       [ 8216.   ,  3931.152],\n       [ 8276.   ,  4184.849],\n       [ 8789.   ,  4544.714],\n       [ 9170.   ,  4125.991],\n       [ 9050.   ,  3694.48 ],\n       [ 8891.   ,  4468.644],\n       [ 8309.   ,  4183.503],\n       [ 7418.   ,  4978.388],\n       [ 7175.   ,  6024.519],\n       [ 7024.   ,  5987.48 ],\n       [ 6613.   ,  5705.485],\n       [ 5946.   ,  4684.847],\n       [ 5521.   ,  4025.674],\n       [ 5552.   ,  3261.025],\n       [ 6286.   ,  2534.88 ],\n       [ 6740.   ,  2564.696],\n       [ 7791.   ,  1817.877],\n       [ 7729.   ,  1838.23 ],\n       [ 7378.   ,  2346.452],\n       [ 6981.   ,  3467.939],\n       [ 6946.   ,  3665.795],\n       [ 6726.   ,  4537.163],\n       [ 6281.   ,  3760.692],\n       [ 6175.   ,  3476.691],\n       [ 6346.   ,  2963.362],\n       [ 6538.   ,  2553.358],\n       [ 6541.   ,  2307.623],\n       [ 6438.   ,  2022.951]])\n</div>"]}}],"execution_count":30},{"cell_type":"markdown","source":["End of Notebook"],"metadata":{}}],"metadata":{"name":"A4.0 - Linear Regression Model (1)1","notebookId":375905},"nbformat":4,"nbformat_minor":0}