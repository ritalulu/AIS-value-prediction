{"cells":[{"cell_type":"code","source":["%sh ls /dbfs/mnt/group-ma755/data/ais*"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/dbfs/mnt/group-ma755/data/ais-test.csv\n/dbfs/mnt/group-ma755/data/ais-train.csv\n</div>"]}}],"execution_count":1},{"cell_type":"markdown","source":["### Setup Libraries"],"metadata":{}},{"cell_type":"markdown","source":["Import `numpy`,`pandas`,`sklearn`. Note the corresponding versions."],"metadata":{}},{"cell_type":"code","source":["import numpy             as np\nimport pandas            as pd\nimport sklearn           \n\nimport datetime as dt\nfrom dateutil import parser\n\nfrom pandas import Series\nfrom pandas import DataFrame\nfrom sklearn import pipeline\nfrom sklearn import preprocessing\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn_pandas import gen_features\nimport sklearn.preprocessing, sklearn.decomposition, \\\n       sklearn.linear_model,  sklearn.pipeline, \\\n       sklearn.metrics\n\nnp.__version__, pd.__version__, sklearn.__version__"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">2</span><span class=\"ansired\">]: </span>(&apos;1.14.3&apos;, &apos;0.18.1&apos;, &apos;0.18.1&apos;)\n</div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["### Setup Dataframe"],"metadata":{}},{"cell_type":"markdown","source":["Read in the dataframe, change the datatype of the `vessel id`. The dataframe `ais_train_df` and `ais_test_df`  will be used throughout this notebook."],"metadata":{}},{"cell_type":"code","source":["ais_train_df = pd.read_csv('/dbfs/mnt/group-ma755/data/ais-train.csv', dtype={'vessel_id': str})\nais_test_df = pd.read_csv('/dbfs/mnt/group-ma755/data/ais-test.csv',dtype={'vessel_id':str}) "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["Read in the external dataframes - We will be using these external dataframes to add features to our training dataset. The description of each of the external dataframes is below:\n- djia_df - The djia_df is a dataframe that shows the closing price of the dow jones index per day. \n- CrudeOil_df - the CrudeOil_df is a dataframe that shows the closing oil price on any given day.\n- DollarIndex_df - The DollarIndex_df shows the foreign exhange value of the US dollar against currencies of a broad group of US trading partners which is again per day.\n- China_Recession_Binary_df - The China_recession_Binary_df is an indicator of the current economic status of China which is a major importer of iron. The CHNRECDM column is a binary varianle (1 & 0 values) where 1 is an indicator of recessionary and 0 ix expansioary."],"metadata":{}},{"cell_type":"code","source":["djia_df = pd.read_csv('/dbfs/FileStore/tables/DJIA.csv')\nCrudeOil_df = pd.read_csv('/dbfs/FileStore/tables/Crude_Oil_Prices___BRENT_EUROPE-e3249.csv')\nDollarIndex_df = pd.read_csv('/dbfs/FileStore/tables/Trade_Weighted_US_Dollar_index-81fa3.csv')\nChina_Recession_Binary_df = pd.read_csv('/dbfs/FileStore/tables/China_Recession_Indicator-0907c.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["Here we are keeping the format and name of the columns consistent. The dataframe `djia_df`, `CrudeOil_df`, `DollarIndex_df`, and `China_Recession_Binary_df` will be used as external features for our analysis."],"metadata":{}},{"cell_type":"code","source":["djia_df['DATE']=pd.to_datetime(djia_df.DATE, format='%Y-%m-%d')\nCrudeOil_df['DATE']=pd.to_datetime(CrudeOil_df.DATE, format='%Y-%m-%d')\nDollarIndex_df['DATE']=pd.to_datetime(DollarIndex_df.DATE, format='%Y-%m-%d')\nChina_Recession_Binary_df['DATE']=pd.to_datetime(China_Recession_Binary_df.DATE, format='%Y-%m-%d')\ndjia_df.columns=['Date','DJIA']\nCrudeOil_df.columns=['Date','Crude Oil Price']\nDollarIndex_df.columns=['Date','Dollar Index']\nChina_Recession_Binary_df.columns=['Date','Indicator']"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"markdown","source":["### Setup for Data Preprocessing Classes `DateTransformer`, `UniqueTransformer`, `AddDatesTransformer`, `MergeFeatureTransformer` and `TypeTransformer`"],"metadata":{}},{"cell_type":"markdown","source":["Create a class `DateTransformer` to sort a dataframe by `Date` variable and put the sequencial `Date` and another column (the default is `Average`) in a new dataframe.\n- The fit method records a dataframe itself in the class.\n- The transform method sort the `Date` in the dataframe X to be transformed and return a new dataframe with the sequencial `Date` and another column (the default is `Average`)."],"metadata":{}},{"cell_type":"code","source":["from sklearn.base import BaseEstimator, TransformerMixin\nclass DateTransformer(BaseEstimator, TransformerMixin):\n  def __init__(self,col_name='Average'):\n    self.col_name = col_name\n  def fit(self, X, y=None):\n    return self\n  def transform(self, X):\n    a=X.sort_values(by=['Date']).copy()\n    a['Date']=pd.to_datetime(X.Date)\n    dates=a['Date']\n    col=a[self.col_name]\n    df=pd.concat([dates, col], axis=1)\n    return df"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["Create a class `UniqueTransformer` to drop duplicate values in a dataframe\n- The fit method records a dataframe itself in the class.\n- The transform method drop duplicate values in the dataframe X to be transformed and return a new time series dataframe."],"metadata":{}},{"cell_type":"code","source":["from sklearn.base import BaseEstimator, TransformerMixin\nclass UniqueTransformer(BaseEstimator, TransformerMixin):\n  def __init__(self,my_var=False):\n    self.my_var = my_var\n  def fit(self, X, y=None):\n    return self\n  def transform(self, X):\n    unique_t_df=X.drop_duplicates()\n    unique_t_df.set_index('Date',inplace=False)\n    return unique_t_df"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"markdown","source":["Create a class `AddDatesTransformer` to include the date numbers into a dataframe\n- The fit method records a dataframe itself in the class.\n- The transform method extracts and includes the `Year`, `Month` and `Day` values in the dataframe X to be transformed and returned in a dataframe. One Data column will be transformed to include three separate 'Year', 'Month' & 'Day' columns."],"metadata":{}},{"cell_type":"code","source":["from sklearn.base import BaseEstimator, TransformerMixin\nclass AddDatesTransformer(BaseEstimator, TransformerMixin):\n  def __init__(self,my_var=False):\n    self.my_var = my_var\n  def fit(self, X, y=None):\n    return self\n  def transform(self, X):\n    X['Year']=pd.DatetimeIndex(X['Date']).year\n    X['Month']=pd.DatetimeIndex(X['Date']).month\n    X['Day']=pd.DatetimeIndex(X['Date']).day  \n    return  X"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["Create a class `MergeFeaturesTransformer` to merge the external variables within a dataframe\n- The fit method records a dataframe itself in the class.\n- The transform method merge the external variables from `djia_df`, `CrudeOil_df`, `DollarIndex_df` and `China_Recession_Binary_df` within the dataframe X to be transformed and return the dataframe."],"metadata":{}},{"cell_type":"code","source":["from sklearn.base import BaseEstimator, TransformerMixin\nclass MergeFeaturesTransformer(BaseEstimator, TransformerMixin):\n  def __init__(self,df_name=djia_df):\n    self.df_name = df_name\n  def fit(self, X, y=None):\n    return self\n  def transform(self, X):\n    X=pd.merge(X, self.df_name, on='Date')  \n    return  X"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["Create a class `TypeTransformer` to deal with the missing values and also change the datatype of the added columns from `object` to `float`.\n- The fit method records a dataframe itself in the class.\n- The transform method deal with the NaN values in `DJIA`, `Crude Oil Price` and `Dollar Index`, and specify the data type as `float` in the dataframe X to be transformed and return the dataframe."],"metadata":{}},{"cell_type":"code","source":["from sklearn.base import BaseEstimator, TransformerMixin\nclass TypeTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self,col_name = 'DJIA'):\n       self.col_name = col_name\n    def fit(self, X, y=None):\n      return self\n    def transform(self, X):\n      X[self.col_name] = pd.to_numeric(X[self.col_name], errors='coerce').fillna(0).astype(float)\n      return  X"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["Now demonstrate the previous five steps using a pipeline `dataset_pipeline`. The dataframe `ais_t_df` is the preprocessed training dataframe, and the dataframe `ais_testnew_df` is the preprocessed test dataframe."],"metadata":{}},{"cell_type":"code","source":["from sklearn import pipeline\nfrom sklearn import preprocessing\n\ndataset_pipeline=pipeline.Pipeline([('Date', DateTransformer()),\n                               ('Unique', UniqueTransformer()),\n                               ('AppendYearMonthDay', AddDatesTransformer()),\n                               ('MergeFeatures', MergeFeaturesTransformer(df_name=djia_df)),\n                               ('MergeFeatures2', MergeFeaturesTransformer(df_name=CrudeOil_df)),\n                               ('MergeFeatures3', MergeFeaturesTransformer(df_name=DollarIndex_df)), \n                               ('MergeFeatures4', MergeFeaturesTransformer(df_name=China_Recession_Binary_df)),   \n                               ('Type', TypeTransformer(col_name='DJIA')),\n                               ('Type2', TypeTransformer(col_name='Crude Oil Price')),\n                               ('Type3', TypeTransformer(col_name='Dollar Index'))\n                               \n                               ])\nais_t_df =dataset_pipeline.fit_transform(ais_train_df)\nais_testnew_df =dataset_pipeline.fit_transform(ais_test_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["### Setup for Feature Generating Classes `LagTransformer` and `WindowTransformer`"],"metadata":{}},{"cell_type":"markdown","source":["Create a class `LagsTransformer` to generate the lagged values in a dataframe\n- The fit method records a dataframe itself in the class.\n- The transform method generate an array in the dataframe X to be transformed and return the array with five columns of lagged `Average` value."],"metadata":{}},{"cell_type":"code","source":["class LagsTransformer(BaseEstimator, TransformerMixin): \n  def __init__(self, n_lags=1, col_name = 'Average'):\n    self.n_lags = n_lags\n    self.col_name = col_name\n  def fit(self, X,y=None):\n    return self\n  def transform(self, X):\n    lag=np.zeros((len(X),self.n_lags))\n    for i in range(self.n_lags):\n      lag[:,i]=X[self.col_name].shift(i)  \n    return  lag"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["Create a class `WindowTransformer` to generate the expanding window statistics values in a dataframe\n- The fit method records a dataframe itself in the class.\n- The transform method generate an array in the dataframe X to be transformed and return the array with three columns of expanding window statistics of the `Average` value."],"metadata":{}},{"cell_type":"code","source":["from sklearn.base import BaseEstimator, TransformerMixin\nclass WindowTransformer(BaseEstimator, TransformerMixin): \n  def __init__(self, col_name = 'Average'):\n    self.col_name = col_name\n  def fit(self, X,y=None):\n    return self\n  def transform(self, X):\n    window=np.zeros((len(X),3))\n    window[:,0]=X[self.col_name].expanding().min()\n    window[:,1]=X[self.col_name].expanding().mean()\n    window[:,2]=X[self.col_name].expanding().max()\n    return  window"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"code","source":["from numpy import *\nclass NaNTransformer(BaseEstimator, TransformerMixin): \n  def fit(self, X, y=None):\n    return self\n  def transform(self, X):\n      where_are_nans=np.isnan(X)\n      X[where_are_nans]=0\n      return  X"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":30},{"cell_type":"markdown","source":["Create the `mapper_lags` object then use it to transform the `Average` variable of the imported dataframe into lagged `Average` variables."],"metadata":{}},{"cell_type":"code","source":["def mapper_lags(n_lags=1, col_name='Average'):\n  return DataFrameMapper([([col_name], LagsTransformer(n_lags=n_lags,col_name=col_name))],input_df=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"markdown","source":["Create the `mapper_binarized_date` object then use it to transform `Month` and `Day` variables of the imported dataframe into binary variables."],"metadata":{}},{"cell_type":"markdown","source":["Create the `mapper_window` object then use it to transform the `Average` variable of the imported dataframe into expanding window statistics of the `Average` variable."],"metadata":{}},{"cell_type":"code","source":["def mapper_window(col_name='Average'):\n  return DataFrameMapper([([col_name], WindowTransformer(col_name=col_name))],input_df=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["Create the `mapper_newdata` object then use it to transform the `DJIA`, `Crude Oil Price`, `Dollar Index` and `Indicator` variables of the imported dataframe into features."],"metadata":{}},{"cell_type":"markdown","source":["Add `feature_generating` to the pipeline and create an array with all sets of transformed variables."],"metadata":{}},{"cell_type":"code","source":["from sklearn import pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.linear_model  import LogisticRegression, LinearRegression\nbinarizer_list=[['Month'],['Day']]\nexternal_data_list=[['DJIA'],['Crude Oil Price'],['Dollar Index'],['Indicator']]\n\npipeline=pipeline.Pipeline([('Date', DateTransformer()),\n                               ('Unique', UniqueTransformer()),\n                               ('AppendYearMonthDay', AddDatesTransformer()),\n                               ('MergeFeatures', MergeFeaturesTransformer()),\n                               ('MergeFeatures2', MergeFeaturesTransformer(df_name=CrudeOil_df)),\n                               ('MergeFeatures3', MergeFeaturesTransformer(df_name=DollarIndex_df)), \n                               ('MergeFeatures4', MergeFeaturesTransformer(df_name=China_Recession_Binary_df)),   \n                               ('Type', TypeTransformer(col_name='DJIA')),\n                               ('Type2', TypeTransformer(col_name='Crude Oil Price')),\n                               ('Type3', TypeTransformer(col_name='Dollar Index')),\n                               \n                               ('feature', FeatureUnion([('lags',mapper_lags(n_lags=20,col_name='Average')),\n                                                         ('class', DataFrameMapper( \n                                                                   gen_features(columns=binarizer_list,\n                                                                   classes=[sklearn.preprocessing.LabelBinarizer]),\n                                                                   input_df=True)),\n                                                         ('new_data', DataFrameMapper(\n                                                                     gen_features(columns=external_data_list,\n                                                                     classes=None),input_df=True)),\n                                                         ('windows',mapper_window(col_name='Average')),\n                                                         ('windows2',mapper_window(col_name='DJIA'))\n                                                                             ])),\n                               ('align',  NaNTransformer())\n                           ])\ntt_x=pipeline.fit_transform(ais_train_df)\ntt_x,tt_x.shape"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">18</span><span class=\"ansired\">]: </span>\n(array([[24795.        ,     0.        ,     0.        , ...,\n         12397.38      , 12397.38      , 12397.38      ],\n        [22697.        , 24795.        ,     0.        , ...,\n         12397.38      , 12407.9       , 12418.42      ],\n        [18729.        , 22697.        , 24795.        , ...,\n         12397.38      , 12410.5       , 12418.42      ],\n        ...,\n        [ 4958.        ,  5156.        ,  5190.        , ...,\n             0.        , 15223.36157472, 18312.39      ],\n        [ 4897.        ,  4958.        ,  5156.        , ...,\n             0.        , 15225.74559118, 18312.39      ],\n        [ 4965.        ,  4897.        ,  4958.        , ...,\n             0.        , 15228.07434434, 18312.39      ]]), (999, 73))\n</div>"]}}],"execution_count":38},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":39}],"metadata":{"name":"A2 - Features New (1)","notebookId":352220},"nbformat":4,"nbformat_minor":0}